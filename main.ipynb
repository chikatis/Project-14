{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring the Variables and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data from files and processing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the Variations in P/T and National Codes\n",
    "variation_folder_path = './Data/code-variations-2015'\n",
    "\n",
    "alberta_building = variation_folder_path + '/CCT Codes Comparison Import Alberta Building v2.csv'\n",
    "bc_buildingA = variation_folder_path + '/CCT Codes Comparison Import BC Building DIV A.csv'\n",
    "bc_buildingB = variation_folder_path + '/CCT Codes Comparison Import BC Building Div B.csv'\n",
    "energy = variation_folder_path + '/CCT Codes Comparison Import Energy Code.csv'\n",
    "fire = variation_folder_path + '/CCT Codes Comparison Import Fire Code.csv'\n",
    "nl_building = variation_folder_path + '/CCT Codes Comparison Import NL Building.csv'\n",
    "on_building_1_and_3 = variation_folder_path + '/CCT Codes Comparison Import ON Building Part 1 and 3.csv'\n",
    "on_building_4_to_7 = variation_folder_path + '/CCT Codes Comparison Import ON Building Part 4 to 7.csv'\n",
    "on_building_9 = variation_folder_path + '/CCT Codes Comparison Import ON Building Part 9 v2.csv'\n",
    "on_building_8_to_12_no_9 = variation_folder_path + '/CCT Codes Comparison Import ON Building Parts 8 10 11 12.csv'\n",
    "pei_building = variation_folder_path + '/CCT Codes Comparison Import PEI Building.csv'\n",
    "plumbing = variation_folder_path + '/CCT Codes Comparison Import Plumbing.csv'\n",
    "qc_building = variation_folder_path + '/CCT Codes Comparison Import QC Building.csv'\n",
    "sk_building = variation_folder_path + '/CCT Codes Comparison Import SK Building.csv'\n",
    "\n",
    "\n",
    "# Paths to the full P/T and National Codes\n",
    "full_2015_folder_path = './Data/code-full-2015'\n",
    "\n",
    "full_national_2015 = full_2015_folder_path + '/National Codes 2015 sentences.xlsx'\n",
    "full_pt_2015 = full_2015_folder_path + '/PT Sentence Data 2015.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to read the data from the file, drop any rows that are completely empty, and print the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in the data, drop any rows that are completely empty, and print the shape of the dataframe\n",
    "def read_data(file_path, code_type):\n",
    "    df = pd.read_csv(file_path, encoding='latin1')\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df['Code Type'] = code_type\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading the Variations files into dataframes, adding a column with *Code Type*, and combining them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(775, 34)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Article Title (FR)', 'National Sentence Number (FR)',\n",
      "       'National Sentence Text', 'P/T Document', 'Matched P/T Division',\n",
      "       'Matched P/T Sentence Number', 'Matched P/T Article Title',\n",
      "       'Matched P/T Article Title (FR)', 'Matched P/T Sentence Number (FR)',\n",
      "       'Matched P/T Sentence Text', 'Text Difference Tracked',\n",
      "       'Difference Type', 'Variation?', 'Variation Label', 'Exception?',\n",
      "       'Comments', 'Code Part', 'Code Article', 'Code Section',\n",
      "       'Code Subsection', 'Code Sentence', 'National Sentence Text (FR)',\n",
      "       'Matched P/T Sentence Text (FR)', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated?', 'Exception Updated?', 'Variation Updated?',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "alberta_building_df = read_data(alberta_building, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Text Difference Tracked', 'Exception',\n",
      "       'Comments', 'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "bc_buildingA_df = read_data(bc_buildingA, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(789, 34)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Article Title (FR)', 'National Sentence Number (FR)',\n",
      "       'National Sentence Text', 'P/T Document', 'Matched P/T Division',\n",
      "       'Matched P/T Sentence Number', 'Matched P/T Article Title',\n",
      "       'Matched P/T Article Title (FR)', 'Matched P/T Sentence Number (FR)',\n",
      "       'Matched P/T Sentence Text', 'Text Difference Tracked',\n",
      "       'Difference Type', 'Variation?', 'Variation Label', 'Exception?',\n",
      "       'Comments', 'Code Part', 'Code Article', 'Code Section',\n",
      "       'Code Subsection', 'Code Sentence', 'National Sentence Text (FR)',\n",
      "       'Matched P/T Sentence Text (FR)', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated?', 'Exception Updated?', 'Variation Updated?',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "bc_buildingB_df = read_data(bc_buildingB, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1389, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Text Difference Tracked', 'Exception',\n",
      "       'Comments', 'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "energy_df = read_data(energy, 'Energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3965, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Text Difference Tracked', 'Exception',\n",
      "       'Comments', 'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "fire_df = read_data(fire, 'Fire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Text Difference Tracked', 'Exception',\n",
      "       'Comments', 'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "nl_building_df = read_data(nl_building, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1874, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'Text Difference Tracked', 'Difference Type', 'Variation',\n",
      "       'Variation Label', 'Exception', 'Comments',\n",
      "       'National Article Title (FR)', 'National Sentence Text (FR)',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)',\n",
      "       'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "on_building_1_and_3_df = read_data(on_building_1_and_3, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1173, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'NationalSentenceNumber', 'National Article Title',\n",
      "       'National Sentence Text', 'P/T Document', 'P/T Division',\n",
      "       'P/TSentenceNumber', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'Difference Type', 'Variation', 'Variation Label',\n",
      "       'Text Difference Tracked', 'Exception', 'Comments',\n",
      "       'National Article Title (FR)', 'National Sentence Text (FR)',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)',\n",
      "       'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "on_building_4_to_7_df = read_data(on_building_4_to_7, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1629, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'P/T Document', 'P/T Division', 'P/T Sentence Number',\n",
      "       'P/T Article Title', 'P/T Sentence Text', 'National Sentence Number',\n",
      "       'National Article Title', 'National Sentence Text',\n",
      "       'Text Difference Tracked', 'Difference Type', 'Variation',\n",
      "       'Variation Label', 'Exception', 'Comments',\n",
      "       'National Article Title (FR)', 'National Sentence Text (FR)',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)',\n",
      "       'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "on_building_9_df = read_data(on_building_9, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'P/T Document', 'P/T Division', 'P/T Sentence Number',\n",
      "       'P/T Article Title', 'P/T Sentence Text', 'National Sentence Number',\n",
      "       'National Article Title', 'National Sentence Text',\n",
      "       'Text Difference Tracked', 'Difference Type', 'Variation',\n",
      "       'Variation Label', 'Exception', 'Comments',\n",
      "       'National Article Title (FR)', 'National Sentence Text (FR)',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)',\n",
      "       'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "on_building_8_to_12_no_9_df = read_data(on_building_8_to_12_no_9, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 34)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Article Title (FR)', 'National Sentence Number (FR)',\n",
      "       'National Sentence Text', 'P/T Document', 'Matched P/T Division',\n",
      "       'Matched P/T Sentence Number', 'Matched P/T Article Title',\n",
      "       'Matched P/T Article Title (FR)', 'Matched P/T Sentence Number (FR)',\n",
      "       'Matched P/T Sentence Text', 'Text Difference Tracked',\n",
      "       'Difference Type', 'Variation?', 'Variation Label', 'Exception?',\n",
      "       'Comments', 'Code Part', 'Code Article', 'Code Section',\n",
      "       'Code Subsection', 'Code Sentence', 'National Sentence Text (FR)',\n",
      "       'Matched P/T Sentence Text (FR)', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated?', 'Exception Updated?', 'Variation Updated?',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pei_building_df = read_data(pei_building, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(849, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Sentence Text (FR)', 'Difference Type', 'Variation',\n",
      "       'Variation Label', 'Text Difference Tracked', 'P/T Article Title (FR)',\n",
      "       'Exception', 'Comments', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated', 'Exception Updated', 'Variation Updated',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "plumbing_df = read_data(plumbing, 'Plumbing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1305, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T(Sentence(Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Exception', 'Comments',\n",
      "       'Text Difference Tracked', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated', 'Exception Updated', 'Variation Updated',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "qc_building_df = read_data(qc_building, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 34)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Article Title (FR)', 'National Sentence Number (FR)',\n",
      "       'National Sentence Text', 'P/T Document', 'Matched P/T Division',\n",
      "       'Matched P/T Sentence Number', 'Matched P/T Article Title',\n",
      "       'Matched P/T Article Title (FR)', 'Matched P/T Sentence Number (FR)',\n",
      "       'Matched P/T Sentence Text', 'Text Difference Tracked',\n",
      "       'Difference Type', 'Variation?', 'Variation Label', 'Exception?',\n",
      "       'Comments', 'Code Part', 'Code Article', 'Code Section',\n",
      "       'Code Subsection', 'Code Sentence', 'National Sentence Text (FR)',\n",
      "       'Matched P/T Sentence Text (FR)', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated?', 'Exception Updated?', 'Variation Updated?',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "sk_building_df = read_data(sk_building, 'Building')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if all the columns of the dataframes, with the same number of columns, are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataframes with 34 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(alberta_building_df.columns == bc_buildingB_df.columns )\n",
    "# print(bc_buildingB_df.columns == pei_building_df.columns)\n",
    "# print(pei_building_df.columns == sk_building_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the dataframes with 34 columns are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataframes with 27 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bc_buildingA_df.columns == energy_df.columns)\n",
    "# print(energy_df.columns == fire_df.columns)\n",
    "# print(fire_df.columns == nl_building_df.columns)\n",
    "# These have the same columns /\\\n",
    "\n",
    "\n",
    "\n",
    "# These do not have the same columns \\/\n",
    "# print(nl_building_df.columns == on_building_1_and_3_df.columns)\n",
    "# print(on_building_1_and_3_df.columns == on_building_4_to_7_df.columns)\n",
    "# print(on_building_4_to_7_df.columns == on_building_8_to_12_no_9_df.columns)\n",
    "# print(on_building_8_to_12_no_9_df.columns == on_building_9_df.columns)\n",
    "# print(on_building_9_df.columns == plumbing_df.columns)\n",
    "# print(plumbing_df.columns == qc_building_df.columns)\n",
    "\n",
    "\n",
    "# Get the column order from nl_building_df\n",
    "column_order = nl_building_df.columns\n",
    "\n",
    "# Reindex the columns of the other dataframes to match the column order of nl_building_df\n",
    "on_building_1_and_3_df = on_building_1_and_3_df.reindex(columns=column_order)\n",
    "on_building_4_to_7_df = on_building_4_to_7_df.reindex(columns=column_order)\n",
    "on_building_8_to_12_no_9_df = on_building_8_to_12_no_9_df.reindex(columns=column_order)\n",
    "on_building_9_df = on_building_9_df.reindex(columns=column_order)\n",
    "plumbing_df = plumbing_df.reindex(columns=column_order)\n",
    "qc_building_df = qc_building_df.reindex(columns=column_order)\n",
    "\n",
    "# Check if the columns are the same\n",
    "# print(nl_building_df.columns == on_building_1_and_3_df.columns)\n",
    "# print(on_building_1_and_3_df.columns == on_building_4_to_7_df.columns)\n",
    "# print(on_building_4_to_7_df.columns == on_building_8_to_12_no_9_df.columns)\n",
    "# print(on_building_8_to_12_no_9_df.columns == on_building_9_df.columns)\n",
    "# print(on_building_9_df.columns == plumbing_df.columns)\n",
    "# print(plumbing_df.columns == qc_building_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining all the dataframes into *variation_df*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame with 34 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1637, 34)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df_1 = pd.concat([alberta_building_df, bc_buildingB_df, pei_building_df, sk_building_df], ignore_index=True)\n",
    "variation_df_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame with 27 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12731, 27)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df_2 = pd.concat([bc_buildingA_df, energy_df, fire_df, nl_building_df, on_building_1_and_3_df, on_building_4_to_7_df, on_building_8_to_12_no_9_df, on_building_9_df, plumbing_df, qc_building_df], ignore_index=True)\n",
    "variation_df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Article Title (FR)', 'National Sentence Number (FR)',\n",
      "       'National Sentence Text', 'P/T Document', 'Matched P/T Division',\n",
      "       'Matched P/T Sentence Number', 'Matched P/T Article Title',\n",
      "       'Matched P/T Article Title (FR)', 'Matched P/T Sentence Number (FR)',\n",
      "       'Matched P/T Sentence Text', 'Text Difference Tracked',\n",
      "       'Difference Type', 'Variation?', 'Variation Label', 'Exception?',\n",
      "       'Comments', 'Code Part', 'Code Article', 'Code Section',\n",
      "       'Code Subsection', 'Code Sentence', 'National Sentence Text (FR)',\n",
      "       'Matched P/T Sentence Text (FR)', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated?', 'Exception Updated?', 'Variation Updated?',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Text Difference Tracked', 'Exception',\n",
      "       'Comments', 'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check for the column names in the two dataframes\n",
    "print(variation_df_1.columns)\n",
    "print(variation_df_2.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changing the names of columns in the *variation_df_1* dataframe to match with those in the *variation_df_2* dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the 'Matched ' and '?' from the column names\n",
    "variation_df_1.columns = variation_df_1.columns.str.replace('Matched ', '') \\\n",
    "    .str.replace('?', '')\n",
    "\n",
    "len(variation_df_2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combining the *variation_df_1* and *variation_df_2* into one dataframe (filling the new columns with Nan values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code Year</th>\n",
       "      <th>Province/Territory</th>\n",
       "      <th>Code Book</th>\n",
       "      <th>National Division</th>\n",
       "      <th>National Sentence Number</th>\n",
       "      <th>National Article Title</th>\n",
       "      <th>National Article Title (FR)</th>\n",
       "      <th>National Sentence Number (FR)</th>\n",
       "      <th>National Sentence Text</th>\n",
       "      <th>P/T Document</th>\n",
       "      <th>...</th>\n",
       "      <th>Code Section</th>\n",
       "      <th>Code Subsection</th>\n",
       "      <th>Code Sentence</th>\n",
       "      <th>National Sentence Text (FR)</th>\n",
       "      <th>P/T Sentence Text (FR)</th>\n",
       "      <th>Text Difference Tracked (FR)</th>\n",
       "      <th>Difference Type Updated</th>\n",
       "      <th>Exception Updated</th>\n",
       "      <th>Variation Updated</th>\n",
       "      <th>Code Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>NBC</td>\n",
       "      <td>Div A</td>\n",
       "      <td>1.1.1.1.(1)</td>\n",
       "      <td>Application of this Code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This Code applies to any one or more of the fo...</td>\n",
       "      <td>NBC AB2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.1.1.1.(1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>NBC</td>\n",
       "      <td>Div A</td>\n",
       "      <td>1.1.1.1.(3)</td>\n",
       "      <td>Application of this Code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NBC AB2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.1.1.1.(3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>NBC</td>\n",
       "      <td>Div A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NBC AB2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.1.1.1.(3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>NBC</td>\n",
       "      <td>Div A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NBC AB2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.1.1.1.(4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>NBC</td>\n",
       "      <td>Div A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NBC AB2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.1.1.1.(5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code Year Province/Territory Code Book National Division  \\\n",
       "0     2015.0                 AB       NBC             Div A   \n",
       "1     2015.0                 AB       NBC             Div A   \n",
       "2     2015.0                 AB       NBC             Div A   \n",
       "3     2015.0                 AB       NBC             Div A   \n",
       "4     2015.0                 AB       NBC             Div A   \n",
       "\n",
       "  National Sentence Number    National Article Title  \\\n",
       "0              1.1.1.1.(1)  Application of this Code   \n",
       "1              1.1.1.1.(3)  Application of this Code   \n",
       "2                      NaN                       NaN   \n",
       "3                      NaN                       NaN   \n",
       "4                      NaN                       NaN   \n",
       "\n",
       "  National Article Title (FR)  National Sentence Number (FR)  \\\n",
       "0                         NaN                            NaN   \n",
       "1                         NaN                            NaN   \n",
       "2                         NaN                            NaN   \n",
       "3                         NaN                            NaN   \n",
       "4                         NaN                            NaN   \n",
       "\n",
       "                              National Sentence Text P/T Document  ...  \\\n",
       "0  This Code applies to any one or more of the fo...   NBC AB2019  ...   \n",
       "1                                                NaN   NBC AB2019  ...   \n",
       "2                                                NaN   NBC AB2019  ...   \n",
       "3                                                NaN   NBC AB2019  ...   \n",
       "4                                                NaN   NBC AB2019  ...   \n",
       "\n",
       "  Code Section Code Subsection Code Sentence National Sentence Text (FR)  \\\n",
       "0          1.1           1.1.1   1.1.1.1.(1)                         NaN   \n",
       "1          1.1           1.1.1   1.1.1.1.(3)                         NaN   \n",
       "2          1.1           1.1.1   1.1.1.1.(3)                         NaN   \n",
       "3          1.1           1.1.1   1.1.1.1.(4)                         NaN   \n",
       "4          1.1           1.1.1   1.1.1.1.(5)                         NaN   \n",
       "\n",
       "   P/T Sentence Text (FR) Text Difference Tracked (FR)  \\\n",
       "0                     NaN                          NaN   \n",
       "1                     NaN                          NaN   \n",
       "2                     NaN                          NaN   \n",
       "3                     NaN                          NaN   \n",
       "4                     NaN                          NaN   \n",
       "\n",
       "   Difference Type Updated Exception Updated Variation Updated Code Type  \n",
       "0                      NaN               NaN               NaN  Building  \n",
       "1                      NaN               NaN               NaN  Building  \n",
       "2                      NaN               NaN               NaN  Building  \n",
       "3                      NaN               NaN               NaN  Building  \n",
       "4                      NaN               NaN               NaN  Building  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df = pd.concat([variation_df_1, variation_df_2], axis=0, ignore_index=True)\n",
    "variation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province/Territory\n",
       "ON     9250\n",
       "QC     2626\n",
       "AB     1109\n",
       "BC      967\n",
       "NL      206\n",
       "NS       83\n",
       "SK       77\n",
       "PE       38\n",
       "NU        8\n",
       "PEI       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df.value_counts('Province/Territory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us change the *PEI* to *PE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Province/Territory\n",
      "ON    9250\n",
      "QC    2626\n",
      "AB    1109\n",
      "BC     967\n",
      "NL     206\n",
      "NS      83\n",
      "SK      77\n",
      "PE      41\n",
      "NU       8\n",
      "Name: count, dtype: int64\n",
      "The shape of the variation_df is (14368, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chikatis\\AppData\\Local\\Temp\\1\\ipykernel_18648\\1751690282.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  variation_df['Province/Territory'].replace({'PEI': 'PE'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "variation_df['Province/Territory'].replace({'PEI': 'PE'}, inplace=True)\n",
    "print(variation_df.value_counts('Province/Territory'))\n",
    "print(f'The shape of the variation_df is {variation_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the combined data into a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Please uncomment the code cell below to do that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variation_df.to_csv('./Data/code-variations-2015/Full 2015 Variation Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will be working with Division B since most of the sentences are not missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for the column names in variation_df and the value counts of P/T Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P/T Division\n",
       "Div B                     13402\n",
       "obc2019_SB-10_Div3_Ch3      620\n",
       "Div A                       109\n",
       "obc2019_SB-10_Div3_Ch1       21\n",
       "NECB2017_DivB                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df['P/T Division'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "National Division\n",
       "Div B    14256\n",
       "Div A      107\n",
       "Div C        5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df['National Division'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(variation_df[variation_df['P/T Division'].isna()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 215 with no missing 'P/T Division' values. We will ignore the 'P/T Division' column since it is the same as 'National Division'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating the rows with Division B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14256, 34)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df_B = variation_df[variation_df['National Division'] == 'Div B']\n",
    "variation_df_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the 2015 variation data based on the Province/Territory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alberta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must also check for the non-NaN National sentence text values in each of these P/T to make sure all the sentences are present in each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1037, 34)\n"
     ]
    }
   ],
   "source": [
    "ab_df = variation_df_B[variation_df_B['Province/Territory'] == 'AB']\n",
    "print(ab_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### British Columbia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(942, 34)\n"
     ]
    }
   ],
   "source": [
    "bc_df = variation_df_B[variation_df_B['Province/Territory'] == 'BC']\n",
    "print(bc_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Newfoundland and Labrador \n",
    "(We won't be using NL since it does not exist in the full code dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206, 34)\n"
     ]
    }
   ],
   "source": [
    "nl_df = variation_df_B[variation_df_B['Province/Territory'] == 'NL']\n",
    "print(nl_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nova Scotia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 34)\n"
     ]
    }
   ],
   "source": [
    "ns_df = variation_df_B[variation_df_B['Province/Territory'] == 'NS']\n",
    "print(ns_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nunavut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 34)\n"
     ]
    }
   ],
   "source": [
    "nu_df = variation_df_B[variation_df_B['Province/Territory'] == 'NU']\n",
    "print(nu_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ontario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9245, 34)\n"
     ]
    }
   ],
   "source": [
    "on_df = variation_df_B[variation_df_B['Province/Territory'] == 'ON']\n",
    "print(on_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prince Edward Island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 34)\n"
     ]
    }
   ],
   "source": [
    "pe_df = variation_df_B[variation_df_B['Province/Territory'] == 'PE']\n",
    "print(pe_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quebec \n",
    "(Won't be using QC for now since it is in French)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2626, 34)\n"
     ]
    }
   ],
   "source": [
    "qc_df = variation_df_B[variation_df_B['Province/Territory'] == 'QC']\n",
    "print(qc_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saskatchewan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 34)\n"
     ]
    }
   ],
   "source": [
    "sk_df = variation_df_B[variation_df_B['Province/Territory'] == 'SK']\n",
    "print(sk_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Full code data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_2015_df = pd.read_excel(full_national_2015)\n",
    "pt_2015_df = pd.read_excel(full_pt_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DOCTYPE', 'PT', 'Code Year', 'Code Book', 'Division', 'Language',\n",
      "       'DOCID', 'DIVISION', 'PT Sentence Number', 'ARTICLE_TITLE',\n",
      "       'PT Sentence Text', 'PARTNUM', 'SECTIONNUM', 'SUBSECTIONNUM',\n",
      "       'ARTICLENUM', 'SENTENCENUM'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'SEQ', 'DOCTYPE', 'DOCID', 'IDWITHINDOC', 'DIVISION', 'PROVISION',\n",
      "       'ARTICLE_TITLE', 'FRAG_DOCUMENT', 'FRAG_DOCUMENT_NOWHITESPACE',\n",
      "       'WORDCOUNT', 'PARTNUM', 'SECTIONNUM', 'SUBSECTIONNUM', 'ARTICLENUM',\n",
      "       'SENTENCENUM'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pt_2015_df.columns)\n",
    "print(national_2015_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating rows from full code data with Division B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIVISION\n",
       "B    13863\n",
       "C      290\n",
       "A      180\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_2015_df['DIVISION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIVISION\n",
       "B    134173\n",
       "C      2700\n",
       "A      1625\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_2015_df['DIVISION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_2015_df_B = national_2015_df[national_2015_df['DIVISION'] == 'B']\n",
    "pt_2015_df_B = pt_2015_df[pt_2015_df['DIVISION'] == 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframes\n",
      "P/T Codes: (134173, 16)\n",
      "National Codes: (13863, 16)\n",
      "\n",
      "Number of missing sentences in\n",
      "P/T Codes: 62664\n",
      "National Codes: 6684\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the dataframes\")\n",
    "print(f\"P/T Codes: {pt_2015_df_B.shape}\")\n",
    "print(f\"National Codes: {national_2015_df_B.shape}\\n\")\n",
    "\n",
    "print(\"Number of missing sentences in\")\n",
    "print(f\"P/T Codes: {pt_2015_df_B['PT Sentence Text'].isna().sum()}\")\n",
    "print(f\"National Codes: {national_2015_df_B['FRAG_DOCUMENT'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the empty sentences and storing the sentence texts in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text sentences in\n",
      "P/T Codes: 71509\n",
      "National Codes: 7179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chikatis\\AppData\\Local\\Temp\\1\\ipykernel_18648\\3390733356.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_2015_df_B.dropna(subset=['PT Sentence Text'], inplace=True)\n",
      "C:\\Users\\chikatis\\AppData\\Local\\Temp\\1\\ipykernel_18648\\3390733356.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  national_2015_df_B.dropna(subset=['FRAG_DOCUMENT'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "pt_2015_df_B.dropna(subset=['PT Sentence Text'], inplace=True)\n",
    "national_2015_df_B.dropna(subset=['FRAG_DOCUMENT'], inplace=True)\n",
    "\n",
    "print(\"Number of text sentences in\")\n",
    "print(f'P/T Codes: {pt_2015_df_B.shape[0]}')\n",
    "print(f'National Codes: {national_2015_df_B.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the national sentence texts into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (5679, 16)\n",
      "Test: (1420, 16)\n",
      "Common sentences between the National train/test: set()\n"
     ]
    }
   ],
   "source": [
    "national_2015_B_unique = national_2015_df_B.drop_duplicates('FRAG_DOCUMENT')\n",
    "\n",
    "national_train, national_test = train_test_split(national_2015_B_unique, test_size=0.2, random_state=SEED)\n",
    "national_train_sentences = national_train['FRAG_DOCUMENT']\n",
    "national_test_sentences = national_test['FRAG_DOCUMENT']\n",
    "\n",
    "print(f\"Train: {national_train.shape}\")\n",
    "print(f\"Test: {national_test.shape}\")\n",
    "print(f\"Common sentences between the National train/test: {set(national_train_sentences) & set(national_test_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7179, 16)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_2015_df_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for the duplicates in the National sentence texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate_values = national_2015_df_B['FRAG_DOCUMENT'][national_2015_df_B.duplicated(subset='FRAG_DOCUMENT')]\n",
    "# duplicate_values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 80 duplicate National sentence texts in the 2015 full code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the 2015 full P/T codes based on individual P/T and further splitting them into train test sets based on the national_train_sentences and national_test_sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to calculate the token similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_similarity(s1, s2):\n",
    "    if isinstance(s1, str) and isinstance(s2, str):\n",
    "        words1 = s1.strip().split()\n",
    "        words2 = s2.strip().split()\n",
    "        # common_words = set(words1) & set(words2)\n",
    "        \n",
    "        common_words = [word for word in words1 if word in words2]\n",
    "        similarity = len(common_words) / max(len(words1), len(words2))\n",
    "        return similarity >= 0.90\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to split individual Province/Territories data into train/test sets and save them as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save_data(df, string):\n",
    "\n",
    "    # Creating a duplicate dataframe to work with\n",
    "    ddf = df\n",
    "\n",
    "    # Isolating the train/test sentences in full national code data with exact match and removing them from the dataframe\n",
    "    train = ddf[ddf['National Sentence Text'].isin(national_train_sentences)]\n",
    "    ddf = ddf[~ddf.index.isin(train.index)]\n",
    "\n",
    "    test = ddf[ddf['National Sentence Text'].isin(national_test_sentences)]\n",
    "    ddf = ddf[~ddf.index.isin(test.index)]\n",
    "\n",
    "\n",
    "    # Checking for sentences with a 90% match in the train and test data and removing them from the dataframe\n",
    "    train = pd.concat(train, ddf[ddf['National Sentence Text'].apply(lambda x: any(token_similarity(x, s) for s in national_train_sentences))], ignore_index=True)\n",
    "    ddf = ddf[~ddf.index.isin(train.index)]\n",
    "    \n",
    "    test = pd.concat(test, ddf[ddf['National Sentence Text'].apply(lambda x: any(token_similarity(x, s) for s in national_test_sentences))], ignore_index=True)\n",
    "    ddf = ddf[~ddf.index.isin(test.index)]\n",
    "\n",
    "\n",
    "    # Checking for empty National Sentence Texts and combining all three dataframes\n",
    "    empty = ddf[ddf['National Sentence Text'].isna()]\n",
    "    main = pd.concat([train, test, empty])\n",
    "    other_national = ddf[~ddf.index.isin(main.index)]\n",
    "\n",
    "    # # Isolating the national sentence texts in the variations data but not in the full data\n",
    "    #  other_national = df[~df.index.isin(main.index)]\n",
    "\n",
    "    empty_train = pd.DataFrame()\n",
    "    empty_test = pd.DataFrame()\n",
    "    \n",
    "    if empty.shape[0] != 0:\n",
    "        total_train = int(np.ceil(0.8 * main.shape[0]))\n",
    "        total_test = main.shape[0] - total_train\n",
    "\n",
    "        empty_train_len = total_train - train.shape[0]\n",
    "        empty_test_len = total_test - test.shape[0]\n",
    "\n",
    "        empty_train, empty_test = train_test_split(empty, train_size=empty_train_len, test_size=empty_test_len, random_state=SEED)\n",
    "\n",
    "    train_set = pd.concat([train, empty_train])\n",
    "    test_set = pd.concat([test, empty_test])\n",
    "\n",
    "    print(f\"{string}\")\n",
    "    print(f\"Full Data: {df.shape[0]}\")\n",
    "    print(f\"Train: {train_set.shape[0]}\")\n",
    "    print(f\"Test: {test_set.shape[0]}\")\n",
    "    print(f\"National sentences in variations data but not in full data: {other_national.shape[0]}\")\n",
    "\n",
    "    # Check if there are any common sentences between the train and test data\n",
    "    print(f\"Common sentences between train and test: {(set(train['National Sentence Text']) & set(test['National Sentence Text']))}\")\n",
    "\n",
    "    # Saving the train and test dataframes as csv files\n",
    "    train_set.to_csv(f'./Data/new-train-test-sets/{string} Train.csv', index=False)\n",
    "    test_set.to_csv(f'./Data/new-train-test-sets/{string} Test.csv', index=False)\n",
    "\n",
    "    return train_set, test_set, other_national"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alberta\n",
      "Full Data: 1037\n",
      "Train: 650\n",
      "Test: 162\n",
      "National sentences in variations data but not in full data: 226\n",
      "Common sentences between train and test: {'The building referred to in Sentence 3.2.2.81.(1) shall be of noncombustible construction, and floor assemblies shall be fire separations with a fire-resistance rating not less than 1 h, mezzanines shall have a fire-resistance rating not less than 1 h, roof assemblies shall have a fire-resistance rating not less than 1 h, and loadbearing walls, columns and arches shall have a fire-resistance rating not less than that required for the supported assembly.'}\n"
     ]
    }
   ],
   "source": [
    "ab_train, ab_test, ab_other = split_and_save_data(ab_df, \"Alberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41     Except as permitted by Articles 3.2.4.10. and ...\n",
       "69     Except as permitted by Sentence 3.2.7.9.(3), t...\n",
       "75     Except as otherwise stated in this Section, ai...\n",
       "76           Non-fixed seating shall conform to the NFC.\n",
       "85     Where Class IA or IB liquids specified in Subs...\n",
       "                             ...                        \n",
       "176                                                  NaN\n",
       "233                                                  NaN\n",
       "397                                                  NaN\n",
       "645                                                  NaN\n",
       "229                                                  NaN\n",
       "Name: National Sentence Text, Length: 723, dtype: object"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_train['National Sentence Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'test_size' parameter of train_test_split must be a float in the range (0.0, 1.0), an int in the range [1, inf) or None. Got -7 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[367], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bc_train, bc_test, bc_other \u001b[38;5;241m=\u001b[39m \u001b[43msplit_and_save_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbc_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBritish Columbia\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[357], line 20\u001b[0m, in \u001b[0;36msplit_and_save_data\u001b[1;34m(df, string)\u001b[0m\n\u001b[0;32m     17\u001b[0m     empty_train_len \u001b[38;5;241m=\u001b[39m total_train \u001b[38;5;241m-\u001b[39m train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     18\u001b[0m     empty_test_len \u001b[38;5;241m=\u001b[39m total_test \u001b[38;5;241m-\u001b[39m test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 20\u001b[0m     empty_train, empty_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mempty_train_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mempty_test_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m train_set \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([train, empty_train])\n\u001b[0;32m     23\u001b[0m test_set \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([test, empty_test])\n",
      "File \u001b[1;32mc:\\Users\\chikatis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:203\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    201\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[1;32m--> 203\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\chikatis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'test_size' parameter of train_test_split must be a float in the range (0.0, 1.0), an int in the range [1, inf) or None. Got -7 instead."
     ]
    }
   ],
   "source": [
    "bc_train, bc_test, bc_other = split_and_save_data(bc_df, \"British Columbia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nova Scotia\n",
      "Full Data: 83\n",
      "Train: 60\n",
      "Test: 15\n",
      "National sentences in variations data but not in full data: 8\n",
      "Common sentences between train and test: 0\n"
     ]
    }
   ],
   "source": [
    "ns_train, ns_test, ns_other = split_and_save_data(ns_df, \"Nova Scotia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nunavut\n",
      "Full Data: 8\n",
      "Train: 6\n",
      "Test: 2\n",
      "National sentences in variations data but not in full data: 0\n",
      "Common sentences between train and test: 0\n"
     ]
    }
   ],
   "source": [
    "nu_train, nu_test, nu_other = split_and_save_data(nu_df, \"Nunavut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontario\n",
      "Full Data: 9245\n",
      "Train: 4992\n",
      "Test: 1247\n",
      "National sentences in variations data but not in full data: 3006\n",
      "Common sentences between train and test: 0\n"
     ]
    }
   ],
   "source": [
    "on_train, on_test, on_other = split_and_save_data(on_df, \"Ontario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prince Edward Island\n",
      "Full Data: 41\n",
      "Train: 31\n",
      "Test: 7\n",
      "National sentences in variations data but not in full data: 3\n",
      "Common sentences between train and test: 0\n"
     ]
    }
   ],
   "source": [
    "pe_train, pe_test, pe_other = split_and_save_data(pe_df, \"Prince Edward Island\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saskatchewan\n",
      "Full Data: 67\n",
      "Train: 32\n",
      "Test: 7\n",
      "National sentences in variations data but not in full data: 28\n",
      "Common sentences between train and test: 0\n"
     ]
    }
   ],
   "source": [
    "sk_train, sk_test, sk_other = split_and_save_data(sk_df, \"Saskatchewan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1655     Buildings shall comply with\\na) the prescripti...\n",
       "3381     1) The maximum permissible occupant load for a...\n",
       "3382     2) The number of occupants permitted to enter ...\n",
       "3390                                     Display Fireworks\n",
       "3391     1) The handling and discharge of fireworks sha...\n",
       "3393     1) When any portion of a fire protection syste...\n",
       "12214     A soil-or-waste pipe shall be of a size not l...\n",
       "12218    Systems for solar heating of potable water sha...\n",
       "Name: National Sentence Text, dtype: object"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns_other['National Sentence Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
