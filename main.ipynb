{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare the Variables and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing (Variations data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the Variations in P/T and National Codes\n",
    "variation_folder_path = './Data/code-variations-2015'\n",
    "\n",
    "alberta_building = variation_folder_path + '/CCT Codes Comparison Import Alberta Building v2.csv'\n",
    "bc_buildingA = variation_folder_path + '/CCT Codes Comparison Import BC Building DIV A.csv'\n",
    "bc_buildingB = variation_folder_path + '/CCT Codes Comparison Import BC Building Div B.csv'\n",
    "energy = variation_folder_path + '/CCT Codes Comparison Import Energy Code.csv'\n",
    "fire = variation_folder_path + '/CCT Codes Comparison Import Fire Code.csv'\n",
    "nl_building = variation_folder_path + '/CCT Codes Comparison Import NL Building.csv'\n",
    "on_building_1_and_3 = variation_folder_path + '/CCT Codes Comparison Import ON Building Part 1 and 3.csv'\n",
    "on_building_4_to_7 = variation_folder_path + '/CCT Codes Comparison Import ON Building Part 4 to 7.csv'\n",
    "on_building_9 = variation_folder_path + '/CCT Codes Comparison Import ON Building Part 9 v2.csv'\n",
    "on_building_8_to_12_no_9 = variation_folder_path + '/CCT Codes Comparison Import ON Building Parts 8 10 11 12.csv'\n",
    "pei_building = variation_folder_path + '/CCT Codes Comparison Import PEI Building.csv'\n",
    "plumbing = variation_folder_path + '/CCT Codes Comparison Import Plumbing.csv'\n",
    "qc_building = variation_folder_path + '/CCT Codes Comparison Import QC Building.csv'\n",
    "sk_building = variation_folder_path + '/CCT Codes Comparison Import SK Building.csv'\n",
    "\n",
    "\n",
    "# Paths to the full P/T and National Codes\n",
    "full_2015_folder_path = './Data/code-full-2015'\n",
    "\n",
    "full_national_2015 = full_2015_folder_path + '/National Codes 2015 sentences.xlsx'\n",
    "full_pt_2015 = full_2015_folder_path + '/PT Sentence Data 2015.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to read the data from the file, drop any rows that are completely empty, and print the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in the data, drop any rows that are completely empty, and print the shape of the dataframe\n",
    "def read_data(file_path, code_type):\n",
    "    df = pd.read_csv(file_path, encoding='latin1')\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df['Code Type'] = code_type\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the Variations files into dataframes, add a column with *Code Type*, and check for the shape and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(775, 34)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Article Title (FR)', 'National Sentence Number (FR)',\n",
      "       'National Sentence Text', 'P/T Document', 'Matched P/T Division',\n",
      "       'Matched P/T Sentence Number', 'Matched P/T Article Title',\n",
      "       'Matched P/T Article Title (FR)', 'Matched P/T Sentence Number (FR)',\n",
      "       'Matched P/T Sentence Text', 'Text Difference Tracked',\n",
      "       'Difference Type', 'Variation?', 'Variation Label', 'Exception?',\n",
      "       'Comments', 'Code Part', 'Code Article', 'Code Section',\n",
      "       'Code Subsection', 'Code Sentence', 'National Sentence Text (FR)',\n",
      "       'Matched P/T Sentence Text (FR)', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated?', 'Exception Updated?', 'Variation Updated?',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "alberta_building_df = read_data(alberta_building, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Text Difference Tracked', 'Exception',\n",
      "       'Comments', 'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "bc_buildingA_df = read_data(bc_buildingA, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(789, 34)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Article Title (FR)', 'National Sentence Number (FR)',\n",
      "       'National Sentence Text', 'P/T Document', 'Matched P/T Division',\n",
      "       'Matched P/T Sentence Number', 'Matched P/T Article Title',\n",
      "       'Matched P/T Article Title (FR)', 'Matched P/T Sentence Number (FR)',\n",
      "       'Matched P/T Sentence Text', 'Text Difference Tracked',\n",
      "       'Difference Type', 'Variation?', 'Variation Label', 'Exception?',\n",
      "       'Comments', 'Code Part', 'Code Article', 'Code Section',\n",
      "       'Code Subsection', 'Code Sentence', 'National Sentence Text (FR)',\n",
      "       'Matched P/T Sentence Text (FR)', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated?', 'Exception Updated?', 'Variation Updated?',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "bc_buildingB_df = read_data(bc_buildingB, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1389, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Text Difference Tracked', 'Exception',\n",
      "       'Comments', 'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "energy_df = read_data(energy, 'Energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3965, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Text Difference Tracked', 'Exception',\n",
      "       'Comments', 'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "fire_df = read_data(fire, 'Fire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Text Difference Tracked', 'Exception',\n",
      "       'Comments', 'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "nl_building_df = read_data(nl_building, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1874, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'Text Difference Tracked', 'Difference Type', 'Variation',\n",
      "       'Variation Label', 'Exception', 'Comments',\n",
      "       'National Article Title (FR)', 'National Sentence Text (FR)',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)',\n",
      "       'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "on_building_1_and_3_df = read_data(on_building_1_and_3, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1173, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'NationalSentenceNumber', 'National Article Title',\n",
      "       'National Sentence Text', 'P/T Document', 'P/T Division',\n",
      "       'P/TSentenceNumber', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'Difference Type', 'Variation', 'Variation Label',\n",
      "       'Text Difference Tracked', 'Exception', 'Comments',\n",
      "       'National Article Title (FR)', 'National Sentence Text (FR)',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)',\n",
      "       'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "on_building_4_to_7_df = read_data(on_building_4_to_7, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1629, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'P/T Document', 'P/T Division', 'P/T Sentence Number',\n",
      "       'P/T Article Title', 'P/T Sentence Text', 'National Sentence Number',\n",
      "       'National Article Title', 'National Sentence Text',\n",
      "       'Text Difference Tracked', 'Difference Type', 'Variation',\n",
      "       'Variation Label', 'Exception', 'Comments',\n",
      "       'National Article Title (FR)', 'National Sentence Text (FR)',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)',\n",
      "       'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "on_building_9_df = read_data(on_building_9, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'P/T Document', 'P/T Division', 'P/T Sentence Number',\n",
      "       'P/T Article Title', 'P/T Sentence Text', 'National Sentence Number',\n",
      "       'National Article Title', 'National Sentence Text',\n",
      "       'Text Difference Tracked', 'Difference Type', 'Variation',\n",
      "       'Variation Label', 'Exception', 'Comments',\n",
      "       'National Article Title (FR)', 'National Sentence Text (FR)',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)',\n",
      "       'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "on_building_8_to_12_no_9_df = read_data(on_building_8_to_12_no_9, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 34)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Article Title (FR)', 'National Sentence Number (FR)',\n",
      "       'National Sentence Text', 'P/T Document', 'Matched P/T Division',\n",
      "       'Matched P/T Sentence Number', 'Matched P/T Article Title',\n",
      "       'Matched P/T Article Title (FR)', 'Matched P/T Sentence Number (FR)',\n",
      "       'Matched P/T Sentence Text', 'Text Difference Tracked',\n",
      "       'Difference Type', 'Variation?', 'Variation Label', 'Exception?',\n",
      "       'Comments', 'Code Part', 'Code Article', 'Code Section',\n",
      "       'Code Subsection', 'Code Sentence', 'National Sentence Text (FR)',\n",
      "       'Matched P/T Sentence Text (FR)', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated?', 'Exception Updated?', 'Variation Updated?',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pei_building_df = read_data(pei_building, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(849, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Sentence Text (FR)', 'Difference Type', 'Variation',\n",
      "       'Variation Label', 'Text Difference Tracked', 'P/T Article Title (FR)',\n",
      "       'Exception', 'Comments', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated', 'Exception Updated', 'Variation Updated',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "plumbing_df = read_data(plumbing, 'Plumbing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1305, 27)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T(Sentence(Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Exception', 'Comments',\n",
      "       'Text Difference Tracked', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated', 'Exception Updated', 'Variation Updated',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "qc_building_df = read_data(qc_building, 'Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 34)\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Article Title (FR)', 'National Sentence Number (FR)',\n",
      "       'National Sentence Text', 'P/T Document', 'Matched P/T Division',\n",
      "       'Matched P/T Sentence Number', 'Matched P/T Article Title',\n",
      "       'Matched P/T Article Title (FR)', 'Matched P/T Sentence Number (FR)',\n",
      "       'Matched P/T Sentence Text', 'Text Difference Tracked',\n",
      "       'Difference Type', 'Variation?', 'Variation Label', 'Exception?',\n",
      "       'Comments', 'Code Part', 'Code Article', 'Code Section',\n",
      "       'Code Subsection', 'Code Sentence', 'National Sentence Text (FR)',\n",
      "       'Matched P/T Sentence Text (FR)', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated?', 'Exception Updated?', 'Variation Updated?',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "sk_building_df = read_data(sk_building, 'Building')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all the columns of the dataframes, with the same number of columns, are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataframes with 34 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(alberta_building_df.columns == bc_buildingB_df.columns )\n",
    "# print(bc_buildingB_df.columns == pei_building_df.columns)\n",
    "# print(pei_building_df.columns == sk_building_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the dataframes with 34 columns are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataframes with 27 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bc_buildingA_df.columns == energy_df.columns)\n",
    "# print(energy_df.columns == fire_df.columns)\n",
    "# print(fire_df.columns == nl_building_df.columns)\n",
    "# These have the same columns /\\\n",
    "\n",
    "\n",
    "\n",
    "# These do not have the same columns \\/\n",
    "# print(nl_building_df.columns == on_building_1_and_3_df.columns)\n",
    "# print(on_building_1_and_3_df.columns == on_building_4_to_7_df.columns)\n",
    "# print(on_building_4_to_7_df.columns == on_building_8_to_12_no_9_df.columns)\n",
    "# print(on_building_8_to_12_no_9_df.columns == on_building_9_df.columns)\n",
    "# print(on_building_9_df.columns == plumbing_df.columns)\n",
    "# print(plumbing_df.columns == qc_building_df.columns)\n",
    "\n",
    "\n",
    "# Get the column order from nl_building_df\n",
    "column_order = nl_building_df.columns\n",
    "\n",
    "# Reindex the columns of the other dataframes to match the column order of nl_building_df\n",
    "on_building_1_and_3_df = on_building_1_and_3_df.reindex(columns=column_order)\n",
    "on_building_4_to_7_df = on_building_4_to_7_df.reindex(columns=column_order)\n",
    "on_building_8_to_12_no_9_df = on_building_8_to_12_no_9_df.reindex(columns=column_order)\n",
    "on_building_9_df = on_building_9_df.reindex(columns=column_order)\n",
    "plumbing_df = plumbing_df.reindex(columns=column_order)\n",
    "qc_building_df = qc_building_df.reindex(columns=column_order)\n",
    "\n",
    "# Check if the columns are the same\n",
    "# print(nl_building_df.columns == on_building_1_and_3_df.columns)\n",
    "# print(on_building_1_and_3_df.columns == on_building_4_to_7_df.columns)\n",
    "# print(on_building_4_to_7_df.columns == on_building_8_to_12_no_9_df.columns)\n",
    "# print(on_building_8_to_12_no_9_df.columns == on_building_9_df.columns)\n",
    "# print(on_building_9_df.columns == plumbing_df.columns)\n",
    "# print(plumbing_df.columns == qc_building_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine all the dataframes into *variation_df*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame with 34 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1637, 34)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df_1 = pd.concat([alberta_building_df, bc_buildingB_df, pei_building_df, sk_building_df], ignore_index=True)\n",
    "variation_df_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame with 27 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12731, 27)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df_2 = pd.concat([bc_buildingA_df, energy_df, fire_df, nl_building_df, on_building_1_and_3_df, on_building_4_to_7_df, on_building_8_to_12_no_9_df, on_building_9_df, plumbing_df, qc_building_df], ignore_index=True)\n",
    "variation_df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Article Title (FR)', 'National Sentence Number (FR)',\n",
      "       'National Sentence Text', 'P/T Document', 'Matched P/T Division',\n",
      "       'Matched P/T Sentence Number', 'Matched P/T Article Title',\n",
      "       'Matched P/T Article Title (FR)', 'Matched P/T Sentence Number (FR)',\n",
      "       'Matched P/T Sentence Text', 'Text Difference Tracked',\n",
      "       'Difference Type', 'Variation?', 'Variation Label', 'Exception?',\n",
      "       'Comments', 'Code Part', 'Code Article', 'Code Section',\n",
      "       'Code Subsection', 'Code Sentence', 'National Sentence Text (FR)',\n",
      "       'Matched P/T Sentence Text (FR)', 'Text Difference Tracked (FR)',\n",
      "       'Difference Type Updated?', 'Exception Updated?', 'Variation Updated?',\n",
      "       'Code Type'],\n",
      "      dtype='object')\n",
      "Index(['Code Year', 'Province/Territory', 'Code Book', 'National Division',\n",
      "       'National Sentence Number', 'National Article Title',\n",
      "       'National Sentence Text', 'National Article Title (FR)',\n",
      "       'National Sentence Text (FR)', 'P/T Document', 'P/T Division',\n",
      "       'P/T Sentence Number', 'P/T Article Title', 'P/T Sentence Text',\n",
      "       'P/T Article Title (FR)', 'P/T Sentence Text (FR)', 'Difference Type',\n",
      "       'Variation', 'Variation Label', 'Text Difference Tracked', 'Exception',\n",
      "       'Comments', 'Text Difference Tracked (FR)', 'Difference Type Updated',\n",
      "       'Exception Updated', 'Variation Updated', 'Code Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check for the column names in the two dataframes\n",
    "print(variation_df_1.columns)\n",
    "print(variation_df_2.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change the names of columns in the *variation_df_1* dataframe to match with those in the *variation_df_2* dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the 'Matched ' and '?' from the column names\n",
    "variation_df_1.columns = variation_df_1.columns.str.replace('Matched ', '') \\\n",
    "    .str.replace('?', '')\n",
    "\n",
    "len(variation_df_2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine the *variation_df_1* and *variation_df_2* into one dataframe (fill the new columns with Nan values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code Year</th>\n",
       "      <th>Province/Territory</th>\n",
       "      <th>Code Book</th>\n",
       "      <th>National Division</th>\n",
       "      <th>National Sentence Number</th>\n",
       "      <th>National Article Title</th>\n",
       "      <th>National Article Title (FR)</th>\n",
       "      <th>National Sentence Number (FR)</th>\n",
       "      <th>National Sentence Text</th>\n",
       "      <th>P/T Document</th>\n",
       "      <th>...</th>\n",
       "      <th>Code Section</th>\n",
       "      <th>Code Subsection</th>\n",
       "      <th>Code Sentence</th>\n",
       "      <th>National Sentence Text (FR)</th>\n",
       "      <th>P/T Sentence Text (FR)</th>\n",
       "      <th>Text Difference Tracked (FR)</th>\n",
       "      <th>Difference Type Updated</th>\n",
       "      <th>Exception Updated</th>\n",
       "      <th>Variation Updated</th>\n",
       "      <th>Code Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>NBC</td>\n",
       "      <td>Div A</td>\n",
       "      <td>1.1.1.1.(1)</td>\n",
       "      <td>Application of this Code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This Code applies to any one or more of the fo...</td>\n",
       "      <td>NBC AB2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.1.1.1.(1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>NBC</td>\n",
       "      <td>Div A</td>\n",
       "      <td>1.1.1.1.(3)</td>\n",
       "      <td>Application of this Code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NBC AB2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.1.1.1.(3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>NBC</td>\n",
       "      <td>Div A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NBC AB2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.1.1.1.(3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>NBC</td>\n",
       "      <td>Div A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NBC AB2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.1.1.1.(4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>NBC</td>\n",
       "      <td>Div A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NBC AB2019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.1.1.1.(5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code Year Province/Territory Code Book National Division  \\\n",
       "0     2015.0                 AB       NBC             Div A   \n",
       "1     2015.0                 AB       NBC             Div A   \n",
       "2     2015.0                 AB       NBC             Div A   \n",
       "3     2015.0                 AB       NBC             Div A   \n",
       "4     2015.0                 AB       NBC             Div A   \n",
       "\n",
       "  National Sentence Number    National Article Title  \\\n",
       "0              1.1.1.1.(1)  Application of this Code   \n",
       "1              1.1.1.1.(3)  Application of this Code   \n",
       "2                      NaN                       NaN   \n",
       "3                      NaN                       NaN   \n",
       "4                      NaN                       NaN   \n",
       "\n",
       "  National Article Title (FR)  National Sentence Number (FR)  \\\n",
       "0                         NaN                            NaN   \n",
       "1                         NaN                            NaN   \n",
       "2                         NaN                            NaN   \n",
       "3                         NaN                            NaN   \n",
       "4                         NaN                            NaN   \n",
       "\n",
       "                              National Sentence Text P/T Document  ...  \\\n",
       "0  This Code applies to any one or more of the fo...   NBC AB2019  ...   \n",
       "1                                                NaN   NBC AB2019  ...   \n",
       "2                                                NaN   NBC AB2019  ...   \n",
       "3                                                NaN   NBC AB2019  ...   \n",
       "4                                                NaN   NBC AB2019  ...   \n",
       "\n",
       "  Code Section Code Subsection Code Sentence National Sentence Text (FR)  \\\n",
       "0          1.1           1.1.1   1.1.1.1.(1)                         NaN   \n",
       "1          1.1           1.1.1   1.1.1.1.(3)                         NaN   \n",
       "2          1.1           1.1.1   1.1.1.1.(3)                         NaN   \n",
       "3          1.1           1.1.1   1.1.1.1.(4)                         NaN   \n",
       "4          1.1           1.1.1   1.1.1.1.(5)                         NaN   \n",
       "\n",
       "   P/T Sentence Text (FR) Text Difference Tracked (FR)  \\\n",
       "0                     NaN                          NaN   \n",
       "1                     NaN                          NaN   \n",
       "2                     NaN                          NaN   \n",
       "3                     NaN                          NaN   \n",
       "4                     NaN                          NaN   \n",
       "\n",
       "   Difference Type Updated Exception Updated Variation Updated Code Type  \n",
       "0                      NaN               NaN               NaN  Building  \n",
       "1                      NaN               NaN               NaN  Building  \n",
       "2                      NaN               NaN               NaN  Building  \n",
       "3                      NaN               NaN               NaN  Building  \n",
       "4                      NaN               NaN               NaN  Building  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df = pd.concat([variation_df_1, variation_df_2], axis=0, ignore_index=True)\n",
    "variation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province/Territory\n",
       "ON     9250\n",
       "QC     2626\n",
       "AB     1109\n",
       "BC      967\n",
       "NL      206\n",
       "NS       83\n",
       "SK       77\n",
       "PE       38\n",
       "NU        8\n",
       "PEI       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df.value_counts('Province/Territory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us change the *PEI* to *PE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Province/Territory\n",
      "ON    9250\n",
      "QC    2626\n",
      "AB    1109\n",
      "BC     967\n",
      "NL     206\n",
      "NS      83\n",
      "SK      77\n",
      "PE      41\n",
      "NU       8\n",
      "Name: count, dtype: int64\n",
      "The shape of the variation_df is (14368, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chikatis\\AppData\\Local\\Temp\\1\\ipykernel_17004\\1751690282.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  variation_df['Province/Territory'].replace({'PEI': 'PE'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "variation_df['Province/Territory'].replace({'PEI': 'PE'}, inplace=True)\n",
    "print(variation_df.value_counts('Province/Territory'))\n",
    "print(f'The shape of the variation_df is {variation_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing white spaces, any quotation marks, any weird characters, leading numerical or alphabetical bullet points, and any new line characters\n",
    "def data_preprocessing(column):\n",
    "    column = column.str.replace('', ' ') \\\n",
    "                    .str.strip() \\\n",
    "                    .str.replace(r'^[\\da-zA-Z]+\\)', ' ', regex=True) \\\n",
    "                    .str.replace('\\n', ' ') \\\n",
    "                    .mask((column == '-') | (column == '_')) \\\n",
    "                    .str.replace('\\x93', ' ') \\\n",
    "                    .str.replace('\\x94', ' ') \\\n",
    "                    .str.replace('\\x96', ' ') \\\n",
    "                    .str.replace('\\x97', ' ') \\\n",
    "                    .str.replace(r' [\\da-zA-Z]+\\) ', ' ', regex=True) \\\n",
    "                    .str.replace(r'\\s{2,}', ' ', regex=True) \\\n",
    "                    .str.replace('?', ' ') \\\n",
    "                    .str.replace(r'^\\d+(\\.\\d+)*[A-Za-z]*\\.?\\s*', '', regex=True) \\\n",
    "                    .str.strip()              \n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31       OS2 Structural Safety\\nAn objective of this Co...\n",
       "39       OH10 Protection from Exterior Noise\\nAn object...\n",
       "40       OH11 Hygiene\\nAn objective of this Code is to ...\n",
       "41       OH12 Privacy\\nAn objective of this Code it to ...\n",
       "47       OP3 Protection of Adjacent Buildings or Facili...\n",
       "                               ...                        \n",
       "13739    Every exit sign shall be visible on approach t...\n",
       "13825    Drain tile and drain pipe for foundation drain...\n",
       "13899    Except as required in Sentence 9.25.2.2.(2), t...\n",
       "13901    Spray-applied polyurethane insulation shall be...\n",
       "14357    Windows and skylights including glazed doors s...\n",
       "Name: P/T Sentence Text, Length: 81, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df['P/T Sentence Text'][~variation_df['P/T Sentence Text'].isna() & variation_df['P/T Sentence Text'].str.contains('')]\n",
    "# variation_df['P/T Sentence Text'][31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the function to process the text data in the variation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df['National Sentence Text'] = data_preprocessing(variation_df['National Sentence Text'])\n",
    "variation_df['P/T Sentence Text'] = data_preprocessing(variation_df['P/T Sentence Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: P/T Sentence Text, dtype: object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df['P/T Sentence Text'][~variation_df['P/T Sentence Text'].isna() & variation_df['P/T Sentence Text'].str.contains('')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P/T Sentence Text\n",
       "Reserved.                                                                                                                                                                                                                                                                                                                                        38\n",
       "Deleted.                                                                                                                                                                                                                                                                                                                                         16\n",
       "Reserved                                                                                                                                                                                                                                                                                                                                          6\n",
       "Flashing shall conform to Subsection 9.26.4.                                                                                                                                                                                                                                                                                                      6\n",
       "Words that appear in italics are defined in Article 1.4.1.2. of Division A.                                                                                                                                                                                                                                                                       6\n",
       "                                                                                                                                                                                                                                                                                                                                                 ..\n",
       "Flames and other sources of ignition shall be eliminated in a building undergoing fumigation or thermal insecticidal fogging.                                                                                                                                                                                                                     1\n",
       "Electric power supply shall be shut off to the premises undergoing fumigation or thermal insecticidal fogging.                                                                                                                                                                                                                                    1\n",
       "The air temperature in a building undergoing fumigation or thermal insecticidal fogging shall be kept sufficiently low to prevent the actuation of any sprinkler system.                                                                                                                                                                          1\n",
       "Protective breathing apparatus shall be made available at the premises undergoing fumigation or thermal insecticidal fogging for all persons in case of emergency.                                                                                                                                                                                1\n",
       "For the purposes of compliance with this Code as required in Clause 1.2.1.1.(1)(b), the objectives and functional statements attributed to the acceptable solutions in this Part shall be the objectives and functional statements listed in Table 11.3.1.1. (See 0te A-1.1.2.1.(1) in Appendix A.) (See 0te D-4.6., Background Information.)     1\n",
       "Name: count, Length: 11363, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df['P/T Sentence Text'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the combined data into a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Please uncomment the code cell below to do that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df.to_csv('./Data/code-variations-2015/Full 2015 Variation Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will be working with Division B since most of the sentences are not missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for the column names in variation_df and the value counts of P/T Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P/T Division\n",
       "Div B                     13402\n",
       "obc2019_SB-10_Div3_Ch3      620\n",
       "Div A                       109\n",
       "obc2019_SB-10_Div3_Ch1       21\n",
       "NECB2017_DivB                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df['P/T Division'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "National Division\n",
       "Div B    14256\n",
       "Div A      107\n",
       "Div C        5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df['National Division'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate the rows with Division B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14256, 34)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_df_B = variation_df[variation_df['National Division'] == 'Div B']\n",
    "variation_df_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the 2015 variation data based on the Province/Territory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alberta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must also check for the non-NaN National sentence text values in each of these P/T to make sure all the sentences are present in each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "divb_path = './Data/2015-divb/code-variations-2015-divb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1037, 34)\n"
     ]
    }
   ],
   "source": [
    "ab_df = variation_df_B[variation_df_B['Province/Territory'] == 'AB']\n",
    "ab_df.to_csv(divb_path + '/DivB AB Variations 2015.csv', index=False)\n",
    "print(ab_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### British Columbia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(942, 34)\n"
     ]
    }
   ],
   "source": [
    "bc_df = variation_df_B[variation_df_B['Province/Territory'] == 'BC']\n",
    "bc_df.to_csv(divb_path + '/DivB BC Variations 2015.csv', index=False)\n",
    "print(bc_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Newfoundland and Labrador \n",
    "(We won't be using NL since it does not exist in the full code dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206, 34)\n"
     ]
    }
   ],
   "source": [
    "nl_df = variation_df_B[variation_df_B['Province/Territory'] == 'NL']\n",
    "print(nl_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nova Scotia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 34)\n"
     ]
    }
   ],
   "source": [
    "ns_df = variation_df_B[variation_df_B['Province/Territory'] == 'NS']\n",
    "ns_df.to_csv(divb_path + '/DivB NS Variations 2015.csv', index=False)\n",
    "print(ns_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nunavut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 34)\n"
     ]
    }
   ],
   "source": [
    "nu_df = variation_df_B[variation_df_B['Province/Territory'] == 'NU']\n",
    "nu_df.to_csv(divb_path + '/DivB NU Variations 2015.csv', index=False)\n",
    "print(nu_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ontario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9245, 34)\n"
     ]
    }
   ],
   "source": [
    "on_df = variation_df_B[variation_df_B['Province/Territory'] == 'ON']\n",
    "on_df.to_csv(divb_path + '/DivB ON Variations 2015.csv', index=False)\n",
    "print(on_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prince Edward Island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 34)\n"
     ]
    }
   ],
   "source": [
    "pe_df = variation_df_B[variation_df_B['Province/Territory'] == 'PE']\n",
    "pe_df.to_csv(divb_path + '/DivB PE Variations 2015.csv', index=False)\n",
    "print(pe_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quebec \n",
    "(Won't be using QC for now since it is in French)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2626, 34)\n"
     ]
    }
   ],
   "source": [
    "qc_df = variation_df_B[variation_df_B['Province/Territory'] == 'QC']\n",
    "print(qc_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saskatchewan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 34)\n"
     ]
    }
   ],
   "source": [
    "sk_df = variation_df_B[variation_df_B['Province/Territory'] == 'SK']\n",
    "sk_df.to_csv(divb_path + '/DivB SK Variations 2015.csv', index=False)\n",
    "print(sk_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing (Full code data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_2015_df = pd.read_excel(full_national_2015)\n",
    "pt_2015_df = pd.read_excel(full_pt_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DOCTYPE', 'PT', 'Code Year', 'Code Book', 'Division', 'Language',\n",
      "       'DOCID', 'DIVISION', 'PT Sentence Number', 'ARTICLE_TITLE',\n",
      "       'PT Sentence Text', 'PARTNUM', 'SECTIONNUM', 'SUBSECTIONNUM',\n",
      "       'ARTICLENUM', 'SENTENCENUM'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'SEQ', 'DOCTYPE', 'DOCID', 'IDWITHINDOC', 'DIVISION', 'PROVISION',\n",
      "       'ARTICLE_TITLE', 'FRAG_DOCUMENT', 'FRAG_DOCUMENT_NOWHITESPACE',\n",
      "       'WORDCOUNT', 'PARTNUM', 'SECTIONNUM', 'SUBSECTIONNUM', 'ARTICLENUM',\n",
      "       'SENTENCENUM'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pt_2015_df.columns)\n",
    "print(national_2015_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Electromagnetic locks that do not incorporate latches, pins or other similar devices to keep the door in the closed position are permitted to be installed on doors in Group B, Division 2 and Division 3 occupancies, provided the building is equipped with a fire alarm system, and sprinklered, the electromagnetic lock releases upon actuation of the alarm signal from the building’s fire alarm system, loss of its power supply and of power to its auxiliary controls, actuation of a manually operated switch that is readily accessible at a constantly attended location within the locked space, and actuation of the manual station installed within 0.5 m of each door and equipped with an auxiliary contact, which directly releases the electromagnetic lock, upon release, the electromagnetic lock requires manual resetting by actuation of the switch referred to in Sentence 3.4.6.16.(5), a legible sign with the words \"EMERGENCY EXIT UNLOCKED BY FIRE ALARM\" written in letters at least 25 mm high with a stroke at least 5 mm wide is permanently mounted on the door, the operation of any by-pass switch, where provided for testing of the fire alarm system, sets off an audible signal and a visual signal at the fire alarm annunciator panel and at the monitoring station referred to in Sentence 3.2.4.7.(4), and emergency lighting is provided at the doors.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_2015_df['PT Sentence Text'][~pt_2015_df['PT Sentence Text'].isna() & pt_2015_df['PT Sentence Text'].str.contains('\"')]\n",
    "pt_2015_df['PT Sentence Text'][73]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess full code data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_2015_df['PT Sentence Text'] = data_preprocessing(pt_2015_df['PT Sentence Text'])\n",
    "national_2015_df['FRAG_DOCUMENT'] = data_preprocessing(national_2015_df['FRAG_DOCUMENT'])\n",
    "\n",
    "pt_2015_df['ARTICLE_TITLE'] = data_preprocessing(pt_2015_df['ARTICLE_TITLE'])\n",
    "national_2015_df['ARTICLE_TITLE'] = data_preprocessing(national_2015_df['ARTICLE_TITLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: FRAG_DOCUMENT, dtype: object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_2015_df['FRAG_DOCUMENT'][~national_2015_df['FRAG_DOCUMENT'].isna() & national_2015_df['FRAG_DOCUMENT'].str.contains('')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate rows from full code data with Division B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIVISION\n",
       "B    13863\n",
       "C      290\n",
       "A      180\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_2015_df['DIVISION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIVISION\n",
       "B    134173\n",
       "C      2700\n",
       "A      1625\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_2015_df['DIVISION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_2015_df_B = national_2015_df[national_2015_df['DIVISION'] == 'B']\n",
    "pt_2015_df_B = pt_2015_df[pt_2015_df['DIVISION'] == 'B']\n",
    "\n",
    "\n",
    "national_2015_df_B.to_csv('./Data/2015-divb/code-full-2015-divb/DivB National Full 2015.csv', index=False)\n",
    "pt_2015_df_B.to_csv('./Data/2015-divb/code-full-2015-divb/DivB PT Full 2015.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframes\n",
      "P/T Codes: (134173, 16)\n",
      "National Codes: (13863, 16)\n",
      "\n",
      "Number of missing sentences in\n",
      "P/T Codes: 62664\n",
      "National Codes: 6684\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the dataframes\")\n",
    "print(f\"P/T Codes: {pt_2015_df_B.shape}\")\n",
    "print(f\"National Codes: {national_2015_df_B.shape}\\n\")\n",
    "\n",
    "print(\"Number of missing sentences in\")\n",
    "print(f\"P/T Codes: {pt_2015_df_B['PT Sentence Text'].isna().sum()}\")\n",
    "print(f\"National Codes: {national_2015_df_B['FRAG_DOCUMENT'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the empty sentences and store the sentence texts in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text sentences in\n",
      "P/T Codes: 71509\n",
      "National Codes: 7179\n"
     ]
    }
   ],
   "source": [
    "pt_2015_df_B = pt_2015_df_B.copy()\n",
    "national_2015_df_B = national_2015_df_B.copy()\n",
    "\n",
    "pt_2015_df_B.dropna(subset=['PT Sentence Text'], inplace=True)\n",
    "national_2015_df_B.dropna(subset=['FRAG_DOCUMENT'], inplace=True)\n",
    "\n",
    "print(\"Number of text sentences in\")    \n",
    "print(f'P/T Codes: {pt_2015_df_B.shape[0]}')\n",
    "print(f'National Codes: {national_2015_df_B.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the national sentence texts into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (5707, 17)\n",
      "Test: (1429, 17)\n",
      "Common sentences between the National train/test: 0\n"
     ]
    }
   ],
   "source": [
    "national_2015_df_B = national_2015_df_B.copy()\n",
    "national_2015_df_B['unique_id'] = national_2015_df_B['FRAG_DOCUMENT'] + national_2015_df_B['ARTICLE_TITLE']\n",
    "\n",
    "# Remove duplicates based on the unique identifier\n",
    "national_2015_df_B = national_2015_df_B.drop_duplicates(subset='unique_id')\n",
    "\n",
    "# Split the unique national sentences into train and test sets\n",
    "unique_train, unique_test = train_test_split(national_2015_df_B['FRAG_DOCUMENT'].unique(), test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Split the full national division B dataset into train/test based on the unique sentences\n",
    "national_train = national_2015_df_B[national_2015_df_B['FRAG_DOCUMENT'].isin(unique_train)]\n",
    "national_test = national_2015_df_B[national_2015_df_B['FRAG_DOCUMENT'].isin(unique_test)]\n",
    "\n",
    "# Print the shapes of the train and test sets and check for common sentences between the two\n",
    "print(f\"Train: {national_train.shape}\")\n",
    "print(f\"Test: {national_test.shape}\")\n",
    "print(f\"Common sentences between the National train/test: {len(set(national_train['FRAG_DOCUMENT']) & set(national_test['FRAG_DOCUMENT']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7136, 17)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_2015_df_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the 2015 individual P/T variations data into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sentence_similarity(s1, s2, threshold):\n",
    "#     if isinstance(s1, str) and isinstance(s2, str):\n",
    "#         words1 = s1.strip().split()\n",
    "#         words2 = s2.strip().split()\n",
    "#         # common_words = set(words1) & set(words2)\n",
    "        \n",
    "#         common_words = [word for word in words1 if word in words2]\n",
    "#         max_len = max(len(words1), len(words2))\n",
    "#         similarity = len(common_words) / max_len\n",
    "\n",
    "#         if max_len <= 20:\n",
    "#             threshold = (max_len - 4) / max_len\n",
    "            \n",
    "#         return similarity >= threshold\n",
    "#     else:\n",
    "#         return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to preprocess the text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(column):\n",
    "    column = column.str.replace('', ' ') \\\n",
    "                    .str.strip() \\\n",
    "                    .str.replace(r'^[\\da-zA-Z]+\\)', ' ', regex=True) \\\n",
    "                    .str.replace('\\n', ' ') \\\n",
    "                    .str.replace('\\x93', ' ') \\\n",
    "                    .str.replace('\\x94', ' ') \\\n",
    "                    .str.replace('\\x96', ' ') \\\n",
    "                    .str.replace('\\x97', ' ') \\\n",
    "                    .str.replace(r' [\\da-zA-Z]+\\) ', ' ', regex=True) \\\n",
    "                    .str.replace(r'\\s{2,}', ' ', regex=True) \\\n",
    "                    .str.replace('?', ' ') \\\n",
    "                    .str.replace(r'^\\d+(\\.\\d+)*[A-Za-z]*\\.?\\s*', '', regex=True) \\\n",
    "                    .str.strip()\n",
    "    # .str.replace(r'\\s*\\(.*?\\)$', '', regex=True) \\\n",
    "\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolate national sentence texts in the National Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_full = national_2015_df_B.copy()\n",
    "national_full = national_full[['FRAG_DOCUMENT']]\n",
    "national_full.rename(columns={'FRAG_DOCUMENT': 'National Full'}, inplace=True)\n",
    "national_full['Processed National Full'] = text_preprocessing(national_full['National Full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the similarties between National sentences in National Full data amd those in P/T data\n",
    "def compute_similarity(national, pt):\n",
    "    words1 = national.strip().split()\n",
    "    words2 = pt.strip().split()\n",
    "    common_words = [word for word in words1 if word in words2]\n",
    "    max_len = max(len(words1), len(words2))\n",
    "    similarity = len(common_words) / max_len\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# For each P/T, find the similarity between each National sentence in National Full and each sentence in P/T data\n",
    "def find_similarity(pt):\n",
    "    results = []\n",
    "    full = pd.read_csv(f'./Data/2015-divb/code-variations-2015-divb/DivB {pt} Variations 2015.csv')\n",
    "    full = full[['National Sentence Text']]\n",
    "    full = full[full['National Sentence Text'].notna()]\n",
    "    full.rename(columns={'National Sentence Text': f'National in {pt}'}, inplace=True)\n",
    "    full[f'Processed National in {pt}'] = text_preprocessing(full[f'National in {pt}'])\n",
    "\n",
    "    # Compare each processed sentence in national_full with all processed sentences in pt_full\n",
    "    for i, row1 in national_full.iterrows():\n",
    "        for j, row2 in full.iterrows():\n",
    "            similarity = compute_similarity(row1['Processed National Full'], row2[f'Processed National in {pt}'])\n",
    "            results.append({\n",
    "                'National Full': row1['National Full'],\n",
    "                f'National in {pt}': row2[f'National in {pt}'],\n",
    "                'Similarity': similarity\n",
    "            })\n",
    "    \n",
    "    # Create a new dataframe with the results\n",
    "    similarity_df = pd.DataFrame(results)\n",
    "\n",
    "    # Sort the dataframe by similarity in descending order\n",
    "    similarity_df = similarity_df.sort_values(by='Similarity', ascending=False)\n",
    "\n",
    "    # Filter out the rows to keep only the highest similarity score for each unique sentence in national_full\n",
    "    unique_national_sentences = set()\n",
    "    filtered_results = []\n",
    "\n",
    "    for index, row in similarity_df.iterrows():\n",
    "        if row['National Full'] not in unique_national_sentences:\n",
    "            filtered_results.append(row)\n",
    "            unique_national_sentences.add(row['National Full'])\n",
    "\n",
    "    \n",
    "    filtered_similarity_df = pd.DataFrame(filtered_results)\n",
    "\n",
    "\n",
    "     # Filter out the rows to keep only the highest similarity score for each unique sentence in pt\n",
    "    unique_variations_sentences = set()\n",
    "    final_filtered_results = []\n",
    "\n",
    "    for index, row in filtered_similarity_df.iterrows():\n",
    "        if row[f'National in {pt}'] not in unique_variations_sentences:\n",
    "            final_filtered_results.append(row)\n",
    "            unique_variations_sentences.add(row[f'National in {pt}'])\n",
    "\n",
    "    # Save the final results to a CSV file\n",
    "    final_filtered_similarity_df = pd.DataFrame(final_filtered_results)\n",
    "    final_filtered_similarity_df.to_csv(f'./Data/new-similarity/{pt} Similarity.csv', index=False)\n",
    "    print(f'{pt} similarity saved successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB similarity saved successfully\n",
      "BC similarity saved successfully\n",
      "NS similarity saved successfully\n",
      "NU similarity saved successfully\n",
      "ON similarity saved successfully\n",
      "PE similarity saved successfully\n",
      "SK similarity saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Store all P/T names in a list\n",
    "pt_name = ['AB', 'BC', 'NS', 'NU', 'ON', 'PE', 'SK']\n",
    "\n",
    "for pt in pt_name:\n",
    "    find_similarity(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to split individual Province/Territories data into train/test sets and save them as csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below only tries to match only the national sentence texts in the variations data and the national sentence texts in the full code data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save_data(df, string, threshold):\n",
    "\n",
    "    # Creating a duplicate dataframe to work with\n",
    "    ddf = df.copy()\n",
    "\n",
    "    # Reading similiarity file for the P/T\n",
    "    similarity = pd.read_csv(f'./Data/new-similarity/{string} Similarity.csv')\n",
    "\n",
    "    # Isolate rows with similarity scores above the threshold\n",
    "    similarity = similarity[similarity['Similarity'] >= threshold]\n",
    "\n",
    "    # Split the similarity dataframe into train and test sets\n",
    "    train_sim = similarity[similarity['National Full'].isin(unique_train)]\n",
    "    test_sim = similarity[similarity['National Full'].isin(unique_test)]\n",
    "\n",
    "    # Splitting the variations data into train and test sets\n",
    "    train = ddf[ddf['National Sentence Text'].isin(train_sim[f'National in {string}'])]\n",
    "    ddf = ddf[~ddf.index.isin(train.index)]\n",
    "\n",
    "    test = ddf[ddf['National Sentence Text'].isin(test_sim[f'National in {string}'])]\n",
    "    ddf = ddf[~ddf.index.isin(test.index)]\n",
    "\n",
    "\n",
    "    # # Isolating the train/test sentences in full national code data with exact match and removing them from the dataframe\n",
    "    # train = ddf[ddf['National Sentence Text'].isin(unique_train)]\n",
    "    # ddf = ddf[~ddf.index.isin(train.index)]\n",
    "\n",
    "    # test = ddf[ddf['National Sentence Text'].isin(unique_test)]\n",
    "    # ddf = ddf[~ddf.index.isin(test.index)]\n",
    "\n",
    "\n",
    "    # # Checking for sentences with a certain threshold match in the train and test data and removing them from the dataframe\n",
    "    # train = pd.concat([train, ddf[ddf['National Sentence Text'].apply(lambda x: any(sentence_similarity(x, s, threshold) for s in unique_train))]])\n",
    "    # ddf = ddf[~ddf.index.isin(train.index)]\n",
    "    \n",
    "    # test = pd.concat([test, ddf[ddf['National Sentence Text'].apply(lambda x: any(sentence_similarity(x, s, threshold) for s in unique_test))]])\n",
    "    # ddf = ddf[~ddf.index.isin(test.index)]\n",
    "\n",
    "\n",
    "    # Checking for empty National Sentence Texts and combining all three dataframes\n",
    "    empty = ddf[ddf['National Sentence Text'].isna()]\n",
    "    main = pd.concat([train, test, empty])\n",
    "    other_national = ddf[~ddf.index.isin(main.index)]\n",
    "\n",
    "    # # Isolating the national sentence texts in the variations data but not in the full data\n",
    "    #  other_national = df[~df.index.isin(main.index)]\n",
    "\n",
    "    empty_train = pd.DataFrame()\n",
    "    empty_test = pd.DataFrame()\n",
    "    \n",
    "    if empty.shape[0] != 0:\n",
    "        total_train = int(np.round(0.8 * main.shape[0]))\n",
    "        total_test = main.shape[0] - total_train\n",
    "\n",
    "        empty_train_len = total_train - train.shape[0]\n",
    "        empty_test_len = total_test - test.shape[0]\n",
    "\n",
    "        empty_train, empty_test = train_test_split(empty, train_size=empty_train_len, test_size=empty_test_len, random_state=SEED)\n",
    "\n",
    "    train_set = pd.concat([train, empty_train])\n",
    "    test_set = pd.concat([test, empty_test])\n",
    "\n",
    "    print(f\"{string}\")\n",
    "    print(f\"Full Data: {df.shape[0]}\")\n",
    "    print(f\"Train: {train_set.shape[0]}\")\n",
    "    print(f\"Test: {test_set.shape[0]}\")\n",
    "    print(f\"National sentences in variations data but not in full data: {other_national.shape[0]}\")\n",
    "\n",
    "    # Check if there are any common sentences between the train and test data\n",
    "    print(f\"Common sentences between train and test: {(set(train['National Sentence Text']) & set(test['National Sentence Text']))}\")\n",
    "\n",
    "    # Saving the train and test dataframes as csv files\n",
    "    train_set.to_csv(f'./Data/pt-train-test-sets/{string} Train.csv', index=False)\n",
    "    test_set.to_csv(f'./Data/pt-train-test-sets/{string} Test.csv', index=False)\n",
    "\n",
    "    return train_set, test_set, other_national"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use function to split Variation data into train/test for individual Province/Territories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB\n",
      "Full Data: 1037\n",
      "Train: 802\n",
      "Test: 200\n",
      "National sentences in variations data but not in full data: 35\n",
      "Common sentences between train and test: set()\n"
     ]
    }
   ],
   "source": [
    "ab_train, ab_test, ab_other = split_and_save_data(ab_df, 'AB', 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC\n",
      "Full Data: 942\n",
      "Train: 754\n",
      "Test: 188\n",
      "National sentences in variations data but not in full data: 0\n",
      "Common sentences between train and test: set()\n"
     ]
    }
   ],
   "source": [
    "bc_train, bc_test, bc_other = split_and_save_data(bc_df, 'BC', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NS\n",
      "Full Data: 83\n",
      "Train: 66\n",
      "Test: 16\n",
      "National sentences in variations data but not in full data: 1\n",
      "Common sentences between train and test: set()\n"
     ]
    }
   ],
   "source": [
    "ns_train, ns_test, ns_other = split_and_save_data(ns_df, 'NS', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NU\n",
      "Full Data: 8\n",
      "Train: 6\n",
      "Test: 2\n",
      "National sentences in variations data but not in full data: 0\n",
      "Common sentences between train and test: set()\n"
     ]
    }
   ],
   "source": [
    "nu_train, nu_test, nu_other = split_and_save_data(nu_df, 'NU', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON\n",
      "Full Data: 9245\n",
      "Train: 7292\n",
      "Test: 1823\n",
      "National sentences in variations data but not in full data: 130\n",
      "Common sentences between train and test: set()\n"
     ]
    }
   ],
   "source": [
    "on_train, on_test, on_other = split_and_save_data(on_df, 'ON', 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PE\n",
      "Full Data: 41\n",
      "Train: 33\n",
      "Test: 8\n",
      "National sentences in variations data but not in full data: 0\n",
      "Common sentences between train and test: set()\n"
     ]
    }
   ],
   "source": [
    "pe_train, pe_test, pe_other = split_and_save_data(pe_df, 'PE', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK\n",
      "Full Data: 67\n",
      "Train: 54\n",
      "Test: 13\n",
      "National sentences in variations data but not in full data: 0\n",
      "Common sentences between train and test: set()\n"
     ]
    }
   ],
   "source": [
    "sk_train, sk_test, sk_other = split_and_save_data(sk_df, 'SK', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save remaining files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the full code national train/test sets as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_train.to_csv('./Data/code-full-2015/full-national-train-test/National Train.csv', index=False)\n",
    "national_test.to_csv('./Data/code-full-2015/full-national-train-test/National Test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the left out data as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_leftout_data(df, string):\n",
    "    df.to_csv(f'./Data/leftout-data/{string} Leftout.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_name = ['AB', 'BC', 'NS', 'NU', 'ON', 'PE', 'SK']\n",
    "\n",
    "for pt in pt_name:\n",
    "    save_leftout_data(eval(f'{pt.lower()}_other'), pt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
